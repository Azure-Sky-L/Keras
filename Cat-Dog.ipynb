{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mzl/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPool2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = 'train/'\n",
    "TEST_DIR = 'test/'\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "print(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 12500\n"
     ]
    }
   ],
   "source": [
    "# 加入全部数据\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "print(len(train_dogs),len(train_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用部分数据 \n",
    "#train_images = train_dogs[:20000] + train_cats[:2000]\n",
    "#test_images =  test_images[:25]\n",
    "random.shuffle(train_images)\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(str(file_path), cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return cv2.resize(img,(ROWS, COLS),interpolation=cv2.INTER_CUBIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, ROWS, COLS,CHANNELS), dtype=np.uint8)\n",
    "\n",
    "    for i,image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 25000\n",
      "Processed 250 of 25000\n",
      "Processed 500 of 25000\n",
      "Processed 750 of 25000\n",
      "Processed 1000 of 25000\n",
      "Processed 1250 of 25000\n",
      "Processed 1500 of 25000\n",
      "Processed 1750 of 25000\n",
      "Processed 2000 of 25000\n",
      "Processed 2250 of 25000\n",
      "Processed 2500 of 25000\n",
      "Processed 2750 of 25000\n",
      "Processed 3000 of 25000\n",
      "Processed 3250 of 25000\n",
      "Processed 3500 of 25000\n",
      "Processed 3750 of 25000\n",
      "Processed 4000 of 25000\n",
      "Processed 4250 of 25000\n",
      "Processed 4500 of 25000\n",
      "Processed 4750 of 25000\n",
      "Processed 5000 of 25000\n",
      "Processed 5250 of 25000\n",
      "Processed 5500 of 25000\n",
      "Processed 5750 of 25000\n",
      "Processed 6000 of 25000\n",
      "Processed 6250 of 25000\n",
      "Processed 6500 of 25000\n",
      "Processed 6750 of 25000\n",
      "Processed 7000 of 25000\n",
      "Processed 7250 of 25000\n",
      "Processed 7500 of 25000\n",
      "Processed 7750 of 25000\n",
      "Processed 8000 of 25000\n",
      "Processed 8250 of 25000\n",
      "Processed 8500 of 25000\n",
      "Processed 8750 of 25000\n",
      "Processed 9000 of 25000\n",
      "Processed 9250 of 25000\n",
      "Processed 9500 of 25000\n",
      "Processed 9750 of 25000\n",
      "Processed 10000 of 25000\n",
      "Processed 10250 of 25000\n",
      "Processed 10500 of 25000\n",
      "Processed 10750 of 25000\n",
      "Processed 11000 of 25000\n",
      "Processed 11250 of 25000\n",
      "Processed 11500 of 25000\n",
      "Processed 11750 of 25000\n",
      "Processed 12000 of 25000\n",
      "Processed 12250 of 25000\n",
      "Processed 12500 of 25000\n",
      "Processed 12750 of 25000\n",
      "Processed 13000 of 25000\n",
      "Processed 13250 of 25000\n",
      "Processed 13500 of 25000\n",
      "Processed 13750 of 25000\n",
      "Processed 14000 of 25000\n",
      "Processed 14250 of 25000\n",
      "Processed 14500 of 25000\n",
      "Processed 14750 of 25000\n",
      "Processed 15000 of 25000\n",
      "Processed 15250 of 25000\n",
      "Processed 15500 of 25000\n",
      "Processed 15750 of 25000\n",
      "Processed 16000 of 25000\n",
      "Processed 16250 of 25000\n",
      "Processed 16500 of 25000\n",
      "Processed 16750 of 25000\n",
      "Processed 17000 of 25000\n",
      "Processed 17250 of 25000\n",
      "Processed 17500 of 25000\n",
      "Processed 17750 of 25000\n",
      "Processed 18000 of 25000\n",
      "Processed 18250 of 25000\n",
      "Processed 18500 of 25000\n",
      "Processed 18750 of 25000\n",
      "Processed 19000 of 25000\n",
      "Processed 19250 of 25000\n",
      "Processed 19500 of 25000\n",
      "Processed 19750 of 25000\n",
      "Processed 20000 of 25000\n",
      "Processed 20250 of 25000\n",
      "Processed 20500 of 25000\n",
      "Processed 20750 of 25000\n",
      "Processed 21000 of 25000\n",
      "Processed 21250 of 25000\n",
      "Processed 21500 of 25000\n",
      "Processed 21750 of 25000\n",
      "Processed 22000 of 25000\n",
      "Processed 22250 of 25000\n",
      "Processed 22500 of 25000\n",
      "Processed 22750 of 25000\n",
      "Processed 23000 of 25000\n",
      "Processed 23250 of 25000\n",
      "Processed 23500 of 25000\n",
      "Processed 23750 of 25000\n",
      "Processed 24000 of 25000\n",
      "Processed 24250 of 25000\n",
      "Processed 24500 of 25000\n",
      "Processed 24750 of 25000\n",
      "Processed 0 of 12500\n",
      "Processed 250 of 12500\n",
      "Processed 500 of 12500\n",
      "Processed 750 of 12500\n",
      "Processed 1000 of 12500\n",
      "Processed 1250 of 12500\n",
      "Processed 1500 of 12500\n",
      "Processed 1750 of 12500\n",
      "Processed 2000 of 12500\n",
      "Processed 2250 of 12500\n",
      "Processed 2500 of 12500\n",
      "Processed 2750 of 12500\n",
      "Processed 3000 of 12500\n",
      "Processed 3250 of 12500\n",
      "Processed 3500 of 12500\n",
      "Processed 3750 of 12500\n",
      "Processed 4000 of 12500\n",
      "Processed 4250 of 12500\n",
      "Processed 4500 of 12500\n",
      "Processed 4750 of 12500\n",
      "Processed 5000 of 12500\n",
      "Processed 5250 of 12500\n",
      "Processed 5500 of 12500\n",
      "Processed 5750 of 12500\n",
      "Processed 6000 of 12500\n",
      "Processed 6250 of 12500\n",
      "Processed 6500 of 12500\n",
      "Processed 6750 of 12500\n",
      "Processed 7000 of 12500\n",
      "Processed 7250 of 12500\n",
      "Processed 7500 of 12500\n",
      "Processed 7750 of 12500\n",
      "Processed 8000 of 12500\n",
      "Processed 8250 of 12500\n",
      "Processed 8500 of 12500\n",
      "Processed 8750 of 12500\n",
      "Processed 9000 of 12500\n",
      "Processed 9250 of 12500\n",
      "Processed 9500 of 12500\n",
      "Processed 9750 of 12500\n",
      "Processed 10000 of 12500\n",
      "Processed 10250 of 12500\n",
      "Processed 10500 of 12500\n",
      "Processed 10750 of 12500\n",
      "Processed 11000 of 12500\n",
      "Processed 11250 of 12500\n",
      "Processed 11500 of 12500\n",
      "Processed 11750 of 12500\n",
      "Processed 12000 of 12500\n",
      "Processed 12250 of 12500\n",
      "(25000, 128, 128, 3)\n",
      "Train shape: (25000, 128, 128, 3)\n",
      "Test shape: (12500, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = prep_data(train_images)\n",
    "test = prep_data(test_images)\n",
    "print(train.shape)\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "print(\"Test shape: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'dog' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    f_score = 2 * (p * r) / (p + r + K.epsilon())\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "\n",
    "def catdog():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (128,128,3)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',  \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy',fscore])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = catdog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 373s 17ms/step - loss: 0.7307 - acc: 0.6029 - fscore: 0.5756 - val_loss: 0.5414 - val_acc: 0.7360 - val_fscore: 0.7502\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 369s 16ms/step - loss: 0.5435 - acc: 0.7242 - fscore: 0.7139 - val_loss: 0.4757 - val_acc: 0.7820 - val_fscore: 0.7745\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 366s 16ms/step - loss: 0.4783 - acc: 0.7728 - fscore: 0.7675 - val_loss: 0.4337 - val_acc: 0.8036 - val_fscore: 0.8058\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 364s 16ms/step - loss: 0.4151 - acc: 0.8156 - fscore: 0.8131 - val_loss: 0.4096 - val_acc: 0.8156 - val_fscore: 0.8181\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 378s 17ms/step - loss: 0.3607 - acc: 0.8414 - fscore: 0.8398 - val_loss: 0.3820 - val_acc: 0.8340 - val_fscore: 0.8308\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 371s 16ms/step - loss: 0.3151 - acc: 0.8652 - fscore: 0.8647 - val_loss: 0.3298 - val_acc: 0.8524 - val_fscore: 0.8582\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 378s 17ms/step - loss: 0.2785 - acc: 0.8816 - fscore: 0.8805 - val_loss: 0.3294 - val_acc: 0.8640 - val_fscore: 0.8621\n",
      "Epoch 8/20\n",
      "22500/22500 [==============================] - 365s 16ms/step - loss: 0.2542 - acc: 0.8958 - fscore: 0.8942 - val_loss: 0.3423 - val_acc: 0.8532 - val_fscore: 0.8526\n",
      "Epoch 9/20\n",
      "22500/22500 [==============================] - 363s 16ms/step - loss: 0.2231 - acc: 0.9087 - fscore: 0.9075 - val_loss: 0.2928 - val_acc: 0.8728 - val_fscore: 0.8758\n",
      "Epoch 10/20\n",
      "22500/22500 [==============================] - 377s 17ms/step - loss: 0.1980 - acc: 0.9189 - fscore: 0.9181 - val_loss: 0.3202 - val_acc: 0.8768 - val_fscore: 0.8765\n",
      "Epoch 11/20\n",
      "22500/22500 [==============================] - 385s 17ms/step - loss: 0.1779 - acc: 0.9293 - fscore: 0.9287 - val_loss: 0.2989 - val_acc: 0.8720 - val_fscore: 0.8749\n",
      "Epoch 12/20\n",
      "22500/22500 [==============================] - 384s 17ms/step - loss: 0.1605 - acc: 0.9368 - fscore: 0.9354 - val_loss: 0.4125 - val_acc: 0.8544 - val_fscore: 0.8641\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# 保存本次模型\n",
    "model_checkpoint = ModelCheckpoint('weights9.h5', monitor='val_loss', save_best_only=True)\n",
    "epochs = 20\n",
    "batch_size = 64 # GPU 不好，不宜过高\n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "\n",
    "predictions = model.fit(train, labels, batch_size = batch_size, epochs = epochs, \n",
    "          validation_split = 0.1, verbose = 1,shuffle=False,callbacks=[history, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 66s 5ms/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mzl/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.155220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.109511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.017239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.962003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.023719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.988997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.025864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.006275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.203018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.006532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.124221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.029490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.492950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     label\n",
       "0    1  0.155220\n",
       "1    2  0.995000\n",
       "2    3  0.109511\n",
       "3    4  0.017239\n",
       "4    5  0.005000\n",
       "5    6  0.962003\n",
       "6    7  0.995000\n",
       "7    8  0.023719\n",
       "8    9  0.988997\n",
       "9   10  0.995000\n",
       "10  11  0.025864\n",
       "11  12  0.006275\n",
       "12  13  0.995000\n",
       "13  14  0.203018\n",
       "14  15  0.995000\n",
       "15  16  0.006532\n",
       "16  17  0.005000\n",
       "17  18  0.124221\n",
       "18  19  0.029490\n",
       "19  20  0.492950"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入模型\n",
    "#model.load_weights('weight.h5')\n",
    "y_pred = model.predict(test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"test2\", (224, 224), shuffle=False, \n",
    "                                         batch_size=64, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
